#Nutrient rerun reconciliation script
#RNN 2021-04-28
  #Pulls in rerun data for TP, TN, SRP, NO3, POC/PON, and POP
  #Compares duplicates/reruns
  #Makes changes to datasets
  #Writes new files for compileNutrientTables.R

# Source the database functions
source("C:/Users/notter/Google Drive/Randi/Database/R/dbUtil.R")

# Set up objects to locate database. Functions in dbUtil require these to be defined ahead of use.
dbdir="C:/Users/notter/Google Drive/Randi/Database/currentDB/" #folder in Database folder that contains the most recent .db file (below)
db="MFEdb_20210423.db" #Change name of db file with every update
dir<-'C:/Users/notter/Google Drive/JonesLabData 2020/TP 2020'

library(tidyverse)

# TP ----
#Post-QC reconciliation:
#find previous TP comments: 
wc<-dbTable("WATER_CHEM")
TP<-wc %>% filter(parameter=="TP" & flag=="1")
comments<-(unique(TP$comments))

#pull duplicates (generated by reruns)
tpOld<- read.csv("Water/Output/compiledData/tpFull_20210216.csv", header = T, stringsAsFactors = F)
dupList<-tpOld[duplicated(tpOld$sample),1] #lists duplicated samples
dup<-tpOld[tpOld$sample%in%dupList,] #lists duplicates and originals
tpOld$sample<-as.character(tpOld$sample)
log<- read.csv("logFiles2020/correctedFiles/unfilteredLogFile.csv",header=T, stringsAsFactors = F)
log<-log[2:nrow(log),]
missing<- log$unfilteredID[!as.character(paste0("U",1:nrow(log))) %in% tpOld$sample]

#pull list of samples originally missing (indicates ID swap errors, use rerun values to determine correct ID's)
tpOld_missing<- read.csv("Water/Output/compiledData/tp_20210216.csv", header = T, stringsAsFactors = F)
wasMissing<- log$unfilteredID[!as.character(paste0("U",1:nrow(log))) %in% tpOld_missing$sample]
  #U138 was recorded twice, U148 was missing

#Determine which of each (original, rerun) pair is correct, or whether to average: 
  #Pairs with 1 original and 1 rerun were QC'd as out of range. Determine if they are within 20%, if yes, average.
  range<-dup %>% group_by(sampleID) %>% filter(n()==2) %>% arrange(sample, desc(runID))
  range %>% group_by(sampleID) %>% summarise(mean = mean(TP))
  range<- range %>% 
    select(-abs, -runID) %>% 
    add_column(dup = rep(rep(c("dup1","dup2"), each = 1), nrow(range)/2)) %>% 
    group_by(sampleID) %>% 
    spread(., dup, TP)
  range<- range %>% 
    rename(comment = "comments") %>% 
    add_column(diff_per = (range$dup1-range$dup2)/range$dup1) %>% 
    rowwise() %>% 
    mutate(avg = mean(c(dup1, dup2)))
  range<- range %>% 
    ungroup(sampleID) %>% 
    mutate(flag = "1") %>% 
    mutate(comment = case_when(diff_per <= .05 & diff_per >= -.05 ~ "failed QA/QC range check; reruns qualitatively similar; original value reported",
                               diff_per <= .2 & diff_per >= -.2 ~ "failed QA/QC range check; rerun within 20% of original reading; average reported",
                               diff_per >= .2 | diff_per <= -.2 ~ "failed QA/QC range check; reruns quite different; rerun reported",
                               TRUE~as.character(comment))) %>% 
    mutate(TPP = case_when(diff_per <= .05 & diff_per >= -.05 ~ dup1,
                           diff_per <= .2 & diff_per >= -.2 ~ avg,
                           diff_per >= .2 | diff_per <= -.2 ~ dup2,
                           TRUE~ -999)) %>%
    rename(comments = "comment")   #2021 all range QC checks were within 20% so the average is reported (U26 and U81)



  #Pairs with >1 original and 1 rerun were duplicate entries and rerun to determine which ID is correct. 
  mixup<- tpOld %>% filter(sample %in% wasMissing)
  mixup[3,1]<-"U148" #changes sample name of correct row
  correctU148<-mixup[4,6:ncol(mixup)] #pulls sample info from correct U148 log info
  mixup[3,6:ncol(mixup)]<-correctU148 #changes sample info for rest of row
  mixup<- mixup[2:3,] #removes extra rows from reruns that helped determine correct info
  
  #make tnNew (finalized rows)
  tpNew<- tpOld_missing %>% 
    bind_rows(mixup) %>% #adds in U138 and U148 which were left out because they were mixed up
    filter(!sample %in% range$sample) %>%  #removes rows that need to be replaced by rows in range
    bind_rows(range) %>% 
    select(colnames(tpOld_missing),flag) %>% 
    arrange(sample)
  
  #check for dups or missing: good to go!
  dupList<-tpNew[duplicated(tpNew$sample),1] 
  dup<-tpNew[tpNew$sample%in%dupList,] 
  missing<- log$unfilteredID[!as.character(paste0("U",1:nrow(log))) %in% tpNew$sample]
  
  #write.csv(tpNew, "Water/Output/compiledData/tpQCd_20210429.csv", row.names = F)

  
# SRP ----
#Post-QC reconciliation:
#find previous TP comments: 
wc<-dbTable("WATER_CHEM")
SRP<-wc %>% filter(parameter=="SRP" & flag=="1")
comments<-(unique(SRP$comments))

#pull duplicates (generated by reruns)
srpOld<- read.csv("Water/Output/compiledData/srpFull_20210217.csv", header = T, stringsAsFactors = F)
dupList<-srpOld[duplicated(srpOld$sample),1] #lists duplicated samples
dup<-srpOld[srpOld$sample%in%dupList,] #lists duplicates and originals
srpOld$sample<-as.character(srpOld$sample)
log<- read.csv("logFiles2020/correctedFiles/filteredLogFile.csv",header=T, stringsAsFactors = F)
log<-log[2:nrow(log),]
missing<- log$filteredID[!as.character(paste0("F",1:nrow(log))) %in% srpOld$sample]

#pull list of samples originally missing (indicates ID swap errors, use rerun values to determine correct ID's)
srpOld_missing<- read.csv("Water/Output/compiledData/srp_20210217.csv", header = T, stringsAsFactors = F)
wasMissing<- log$filteredID[!as.character(paste0("F",1:nrow(log))) %in% srpOld_missing$sample]
#none originally missing (5 reruns * 2 = 10 rows)

#Determine which of each (original, rerun) pair is correct, or whether to average: 
#Pairs with 1 original and 1 rerun were QC'd as out of range. Determine if they are within 20%, if yes, average.
range<-dup %>% group_by(sampleID) %>% filter(n()==2) %>% arrange(sample, desc(runID))
range<- range %>% 
  select(-abs, -runID) %>% 
  add_column(dup = rep(rep(c("dup1","dup2"), each = 1), nrow(range)/2)) %>% 
  group_by(sampleID) %>% 
  spread(., dup, SRP)
range<- range %>% 
  rename(comment = "comments") %>% 
  add_column(diff_per = (range$dup1-range$dup2)/range$dup1) %>% 
  rowwise() %>% 
  mutate(avg = mean(c(dup1, dup2)))
range<- range %>% 
  ungroup(sampleID) %>% 
  mutate(flag = "1") %>% 
  mutate(comment = case_when(diff_per <= .05 & diff_per >= -.05 ~ "failed QA/QC range check; reruns qualitatively similar; original value reported",
                             diff_per <= .2 & diff_per >= -.2 ~ "failed QA/QC range check; rerun within 20% of original reading; average reported",
                             diff_per >= .2 | diff_per <= -.2 ~ "failed QA/QC range check; reruns quite different; rerun reported",
                             TRUE~as.character(comment))) %>% 
  mutate(SRP = case_when(diff_per <= .05 & diff_per >= -.05 ~ dup1,
                         diff_per <= .2 & diff_per >= -.2 ~ avg,
                         diff_per >= .2 | diff_per <= -.2 ~ dup2,
                         TRUE~ -999)) %>%
  rename(comments = "comment") 


#make tnNew (finalized rows)
srpNew<- srpOld_missing %>% 
  #bind_rows(mixup) %>% #adds in U138 and U148 which were left out because they were mixed up
  filter(!sample %in% range$sample) %>%  #removes rows that need to be replaced by rows in range
  bind_rows(range) %>% 
  select(colnames(srpOld_missing),flag) %>% 
  arrange(sample)

#check for dups or missing: good to go!
dupList<-srpNew[duplicated(srpNew$sample),1] 
dup<-srpNew[srpNew$sample%in%dupList,] 
missing<- log$unfilteredID[!as.character(paste0("U",1:nrow(log))) %in% srpNew$sample]

#write.csv(srpNew, "Water/Output/compiledData/srpQCd_20210429.csv", row.names = F)
  
  

# NO3 ----
#Post-QC reconciliation:
#find previous TP comments: 
wc<-dbTable("WATER_CHEM")
NO3<-wc %>% filter(parameter=="nitrate" & flag=="1")
comments<-(unique(NO3$comments))

#pull duplicates (generated by reruns)
no3Old<- read.csv("Water/Output/compiledData/no3Full_20210217.csv", header = T, stringsAsFactors = F)
dupList<-no3Old[duplicated(no3Old$sample),1] #lists duplicated samples
dup<-no3Old[no3Old$sample%in%dupList,] #lists duplicates and originals
no3Old$sample<-as.character(no3Old$sample)
missing<- log$unfilteredID[!as.character(paste0("F",1:nrow(log))) %in% no3Old$sample]

#pull list of samples originally missing (indicates ID swap errors, use rerun values to determine correct ID's)
no3Old_missing<- read.csv("Water/Output/compiledData/no3_20210217.csv", header = T, stringsAsFactors = F)
wasMissing<- log$unfilteredID[!as.character(paste0("F",1:nrow(log))) %in% no3Old_missing$sample]


#Determine which of each (original, rerun) pair is correct, or whether to average: 
#Pairs with 1 original and 1 rerun were QC'd as out of range. Determine if they are within 20%, if yes, average.
range<-dup %>% group_by(sampleID) %>% filter(n()==2) %>% arrange(sample, desc(runID))
range %>% group_by(sampleID) %>% summarise(mean = mean(NO3))
range<- range %>% 
  select(-abs, -runID, -dilution) %>% 
  add_column(dup = rep(rep(c("dup1","dup2"), each = 1), nrow(range)/2)) %>% 
  group_by(sampleID) %>% 
  spread(., dup, NO3)
range<- range %>% 
  rename(comment = "comments") %>% 
  add_column(diff_per = (range$dup1-range$dup2)/range$dup1) %>% 
  rowwise() %>% 
  mutate(avg = mean(c(dup1, dup2)))
range<- range %>% 
  ungroup(sampleID) %>% 
  mutate(flag = "1") %>% 
  mutate(comment = case_when(diff_per <= .05 & diff_per >= -.05 ~ "failed QA/QC range check; reruns qualitatively similar; original value reported",
                             diff_per <= .2 & diff_per >= -.2 ~ "failed QA/QC range check; rerun within 20% of original reading; average reported",
                             diff_per >= .2 | diff_per <= -.2 ~ "failed QA/QC range check; reruns quite different; rerun reported",
                             TRUE~as.character(comment))) %>% 
  mutate(NO3 = case_when(diff_per <= .05 & diff_per >= -.05 ~ dup1,
                         diff_per <= .2 & diff_per >= -.2 ~ avg,
                         diff_per >= .2 | diff_per <= -.2 ~ dup2,
                         TRUE~ -999)) %>%
  rename(comments = "comment") 
#2021 all range QC checks were within 20% so the average is reported (U26 and U81)

#make tnNew (finalized rows)
no3New<- no3Old_missing %>% 
  #bind_rows(mixup) %>% #adds in U138 and U148 which were left out because they were mixed up
  filter(!sample %in% range$sample) %>%  #removes rows that need to be replaced by rows in range
  bind_rows(range) %>% 
  select(colnames(no3Old_missing),flag) %>% 
  arrange(sample)

#check for dups or missing: good to go!
dupList<-no3New[duplicated(no3New$sample),1] 
dup<-no3New[no3New$sample%in%dupList,] 
missing<- log$unfilteredID[!as.character(paste0("U",1:nrow(log))) %in% no3New$sample]

#write.csv(no3New, "Water/Output/compiledData/no3QCd_20210429.csv", row.names = F)


# TN ----
#Post-QC reconciliation:
#find previous TP comments: 
wc<-dbTable("WATER_CHEM")
TN<-wc %>% filter(parameter=="TN" & flag=="1")
comments<-(unique(TN$comments))

#pull duplicates (generated by reruns)
tnOld<- read.csv("Water/Output/compiledData/tnFull_20210216.csv", header = T, stringsAsFactors = F)
dupList<-tnOld[duplicated(tnOld$sample),1] #lists duplicated samples
dup<-tnOld[tnOld$sample%in%dupList,] #lists duplicates and originals
tnOld$sample<-as.character(tnOld$sample)
log<- read.csv("logFiles2020/correctedFiles/unfilteredLogFile.csv",header=T, stringsAsFactors = F)
log<-log[2:nrow(log),]
missing<- log$unfilteredID[!as.character(paste0("U",1:nrow(log))) %in% tnOld$sample]

#pull list of samples originally missing (indicates ID swap errors, use rerun values to determine correct ID's)
tnOld_missing<- read.csv("Water/Output/compiledData/tnCorrected_20210429.csv", header = T, stringsAsFactors = F)
wasMissing<- log$unfilteredID[!as.character(paste0("U",1:nrow(log))) %in% tnOld_missing$sample]
#U138 was recorded twice, U148 was missing

#Determine which of each (original, rerun) pair is correct, or whether to average: 
#Pairs with 1 original and 1 rerun were QC'd as out of range. Determine if they are within 20%, if yes, average.
range<-dup %>% group_by(sampleID) %>% filter(n()==2) %>% arrange(sample, desc(runID))
range %>% group_by(sampleID) %>% summarise(mean = mean(TN))
range<- range %>% 
  select(-abs, -runID, -dilution) %>% 
  add_column(dup = rep(rep(c("dup1","dup2"), each = 1), nrow(range)/2)) %>% 
  group_by(sampleID) %>% 
  spread(., dup, TN)
range<- range %>% 
  rename(comment = "comments") %>% 
  add_column(diff_per = (range$dup2-range$dup1)/range$dup2) %>% 
  rowwise() %>% 
  mutate(avg = mean(c(dup1, dup2)))
range<- range %>% 
  ungroup(sampleID) %>% 
  mutate(flag = "1") %>% 
  mutate(comment = case_when(diff_per <= .05 & diff_per >= -.05 ~ "failed QA/QC range check; reruns qualitatively similar; original value reported",
                             diff_per <= .2 & diff_per >= -.2 ~ "failed QA/QC range check; rerun within 20% of original reading; average reported",
                             diff_per >= .2 | diff_per <= -.2 ~ "failed QA/QC range check; reruns quite different; rerun reported",
                             TRUE~as.character(comment))) %>% 
  mutate(TN = case_when(diff_per <= .05 & diff_per >= -.05 ~ dup1,
                         diff_per <= .2 & diff_per >= -.2 ~ avg,
                         diff_per >= .2 | diff_per <= -.2 ~ dup2,
                         TRUE~ -999)) %>%
  rename(comments = "comment") %>%
  filter(sample == "U152") #others were incorrectly flagged due to dilution error that I corrected later
#1 range check needs to be corrected to rerun value


#Pairs with >1 original and 1 rerun were duplicate entries and rerun to determine which ID is correct. 
mixup<- tnOld %>% filter(sample %in% wasMissing)
mixup<-mixup[3:4,]

#make tnNew (finalized rows)
tnNew<- tnOld_missing %>% 
  bind_rows(mixup) %>% #adds in U138 and U148 which were left out because they were mixed up
  filter(!sample %in% range$sample) %>%  #removes rows that need to be replaced by rows in range
  bind_rows(range) %>% 
  select(colnames(tnOld_missing),flag) %>% 
  arrange(sample)
 
#check for dups or missing: good to go!
dupList<-tnNew[duplicated(tnNew$sample),1] 
dup<-tnNew[tnNew$sample%in%dupList,] 
missing<- log$unfilteredID[!as.character(paste0("U",1:nrow(log))) %in% tnNew$sample]

#write.csv(tnNew, "Water/Output/compiledData/tnQCd_20210429.csv", row.names = F)

#POP----
#Post-QC reconciliation:
#find previous TP comments:
wc<-dbTable("WATER_CHEM")
POP<-wc %>% filter(parameter=="particulateP" & flag=="1")
comments<-(unique(POP$comments))

#POP - 2020----
#pull duplicates (generated by reruns)
popOld<- read.csv("Water/Output/compiledData/POP2020full_20210505.csv", header = T, stringsAsFactors = F)
dupList<-popOld[duplicated(popOld$sample),1] #lists duplicated samples
dup<-popOld[popOld$sample%in%dupList,] #lists duplicates and originals
popOld$sample<-as.character(popOld$sample)
log<- read.csv("logFiles2020/correctedFiles/pocLogFile.csv",header=T, stringsAsFactors = F)
log<-log[2:nrow(log),]
missing<- log$pocID[!as.character(paste0("P",1:nrow(log))) %in% popOld$sample]

#pull list of samples originally missing (indicates ID swap errors, use rerun values to determine correct ID's)
popOld_missing<- read.csv("Water/Output/compiledData/POP2020_20210219.csv", header = T, stringsAsFactors = F)
popOld_missing$POP<- (popOld_missing$POPinBottle *.03)/(popOld_missing$volFiltered/1000) #Formula: (Concentration in bottle/ 30 ml vol water added to filter in L)/(filter volume (mL)/1000) = (mass POP on filter (ug))/(volume filtered (L)) = POP ug/L
wasMissing<- log$pocID[!as.character(paste0("P",1:nrow(log))) %in% popOld_missing$sample]
#U138 was recorded twice, U148 was missing

#Determine which of each (original, rerun) pair is correct, or whether to average:
#no range errors for 2020 pop:
  #P6 and P9 were both labeled "P6". Reran P9 @ 8.414406 which equals the fake "P6" @ 8.700523

fix<- dup[1,] %>% 
  mutate(sample = "P9") %>% 
  select(sample, abs, df, runID, POPinBottle, POP) %>% 
  rename(pocID = "sample") %>% 
  left_join(log, by.x = "sample", by.y="pocID") %>% 
  rename(sample = "pocID") %>% 
  select(colnames(dup), -replicate) %>% 
  mutate(replicate = 1) %>% 
  bind_rows(dup[2,])

mixup<- popOld %>% filter(sample %in% wasMissing & sample!="P6")
           

#make popNew (finalized rows)
pop2020<- popOld_missing %>%
  bind_rows(mixup) %>% 
  filter(!sample %in% fix$sample) %>%  #removes rows that need to be replaced by rows in range
  bind_rows(fix) %>%
  select(colnames(popOld)) %>%
  add_column(flag = NA) %>% 
  arrange(sample)

#check for dups or missing: good to go!
dupList<-pop2020[duplicated(pop2020$sample),1]
dup<-pop2020[pop2020$sample%in%dupList,]
missing<- log$pocID[!as.character(paste0("P",1:nrow(log))) %in% pop2020$sample]

#write.csv(pop2020, "Water/Output/compiledData/pop2020QCd_20210505.csv", row.names = F)

#POP - 2019----
#pull duplicates (generated by reruns)
popOld<- read.csv("Water/Output/compiledData/POP2019full_20210505.csv", header = T, stringsAsFactors = F)
dupList<-popOld[duplicated(popOld$sample),1] #lists duplicated samples
dup<-popOld[popOld$sample%in%dupList,] #lists duplicates and originals
popOld$sample<-as.character(popOld$sample)
log<- read.csv("C:/Users/notter/Box/MFE/Archives/OneDriveArchive/Summer 2019/Limno/limnoEntryTool/logFiles2019/pocLogFile.csv", header = T, stringsAsFactors = F)
log<-log[2:nrow(log),]
missing<- log$pocID[!as.character(paste0("P",1:nrow(log))) %in% popOld$sample]

#pull list of samples originally missing (indicates ID swap errors, use rerun values to determine correct ID's)
popOld_missing<- read.csv("Water/Output/compiledData/POP2019_20210219.csv", header = T, stringsAsFactors = F)
popOld_missing$POP<- (popOld_missing$POPinBottle *.03)/(popOld_missing$volFiltered/1000) #Formula: (Concentration in bottle/ 30 ml vol water added to filter in L)/(filter volume (mL)/1000) = (mass POP on filter (ug))/(volume filtered (L)) = POP ug/L
wasMissing<- log$pocID[!as.character(paste0("P",1:nrow(log))) %in% popOld_missing$sample]


#Determine which of each (original, rerun) pair is correct, or whether to average: 
#Pairs with 1 original and 1 rerun were QC'd as out of range. Determine if they are within 20%, if yes, average.
range<-dup %>% group_by(sampleID) %>% filter(n()==2) %>% arrange(sample, desc(runID))
range %>% group_by(sampleID) %>% summarise(mean = mean(POP))
range<- range %>% 
  select(-abs, -runID, -POPinBottle) %>% 
  add_column(dup = rep(rep(c("dup1","dup2"), each = 1), nrow(range)/2)) %>% 
  group_by(sampleID) %>% 
  spread(., dup, POP)
range<- range %>% 
  rename(comment = "comments") %>% 
  add_column(diff_per = (range$dup1-range$dup2)/range$dup1) %>% 
  rowwise() %>% 
  mutate(avg = mean(c(dup1, dup2)))
range<- range %>% 
  ungroup(sampleID) %>% 
  mutate(flag = "1") %>% 
  mutate(comment = case_when(diff_per <= .05 & diff_per >= -.05 ~ "failed QA/QC range check; reruns qualitatively similar; original value reported",
                             diff_per <= .2 & diff_per >= -.2 ~ "failed QA/QC range check; rerun within 20% of original reading; average reported",
                             diff_per >= .2 | diff_per <= -.2 ~ "failed QA/QC range check; reruns quite different; rerun reported",
                             TRUE~as.character(comment))) %>% 
  mutate(POP = case_when(diff_per <= .05 & diff_per >= -.05 ~ dup1,
                         diff_per <= .2 & diff_per >= -.2 ~ avg,
                         diff_per >= .2 | diff_per <= -.2 ~ dup2,
                         TRUE~ -999)) %>%
  rename(comments = "comment")   #2021 all range QC checks were within 20% so the average is reported (U26 and U81)



#originally missing. 
add<- popOld %>% filter(sample %in% wasMissing)


#make tnNew (finalized rows)
pop2019<- popOld_missing %>% 
  bind_rows(add) %>% #adds in U138 and U148 which were left out because they were mixed up
  filter(!sample %in% range$sample) %>%  #removes rows that need to be replaced by rows in range
  bind_rows(range) %>% 
  select(colnames(popOld_missing),flag) %>% 
  arrange(sample)


#check for dups or missing: good to go!
dupList<-pop2019[duplicated(pop2019$sample),1]
dup<-pop2019[pop2019$sample%in%dupList,]
missing<- log$pocID[!as.character(paste0("P",1:nrow(log))) %in% pop2019$sample]

#write.csv(pop2019, "Water/Output/compiledData/pop2019QCd_20210505.csv", row.names = F)

checkCols(pop2020,pop2019)
popM<-bind_rows(pop2019,pop2020)
write.csv(popM, "Water/Output/compiledData/popQCd_20210505.csv", row.names = F)

#POC----
#Post-QC reconciliation:
#find previous TP comments: 
wc<-dbTable("WATER_CHEM")
POC<-wc %>% filter(parameter%in%c("POC","PON") & flag=="1")
comments<-(unique(POC$comments))

#pull duplicates (generated by reruns)
pocOld<- read.csv("Water/Output/compiledData/pocFull_20210505.csv", header = T, stringsAsFactors = F)
dupList<- pocOld %>% 
  group_by(sampleID) %>% 
  filter(n()>2)
missingList<- unique(pocOld$sampleID[is.na(pocOld$parameterValue)])
dup<- dupList %>% filter(!sampleID %in% missingList)


#pull list of samples originally missing (indicates ID swap errors, use rerun values to determine correct ID's)
wasMissing<- dupList %>% filter(sampleID %in% missingList)


#Determine which of each (original, rerun) pair is correct, or whether to average: 
#Pairs with 1 original and 1 rerun were QC'd as out of range. Determine if they are within 20%, if yes, average.
#range<-dup %>% group_by(sampleID) %>% filter(n()==2) %>% arrange(sampleID, desc(updateID))
range<- dup %>%  arrange(sampleID, parameter)
range %>% group_by(sampleID, parameter) %>% summarise(mean = mean(parameterValue))
range<- range %>% 
  select(-updateID) %>% 
  add_column(dup = rep(rep(c("dup1","dup2"), each = 1), nrow(range)/2)) %>%
  group_by(sampleID, parameter) %>% 
  spread(., dup, parameterValue)
i=1
for(i in 1:nrow(range)){
  range$pocID[i]<- samples$pocID[range$sampleID[i]==samples$sampleID]
}
qcC<-c("P111","P181","P261","P38","P159")
qcN<-c("P232","P261","P38")
rangePOC<- range[range$parameter == "POC" & range$pocID %in% qcC,]
rangePON<- range[range$parameter == "PON" & range$pocID %in% qcN,]
range<- rbind(rangePOC, rangePON)
range<- range %>% 
  rename(comment = "comments") %>% 
  add_column(diff_per = (range$dup1-range$dup2)/range$dup1) %>% 
  rowwise() %>% 
  mutate(avg = mean(c(dup1, dup2)))
range<- range %>% 
  ungroup(sampleID) %>% 
  mutate(flag = "1") %>% 
  mutate(comment = case_when(diff_per <= .05 & diff_per >= -.05 ~ "failed QA/QC range check; reruns qualitatively similar; original value reported",
                             diff_per <= .2 & diff_per >= -.2 ~ "failed QA/QC range check; rerun within 20% of original reading; average reported",
                             diff_per >= .2 | diff_per <= -.2 ~ "failed QA/QC range check; reruns quite different; rerun reported",
                             TRUE~as.character(comment))) %>% 
  mutate(parameterValue = case_when(diff_per <= .05 & diff_per >= -.05 ~ dup1,
                         diff_per <= .2 & diff_per >= -.2 ~ avg,
                         diff_per >= .2 | diff_per <= -.2 ~ dup2,
                         TRUE~ -999)) %>%
  rename(comments = "comment") %>%    #2021 all range QC checks were within 20% so the average is reported (U26 and U81)
  add_column(sample = paste(range$sampleID,range$parameter,sep="_"))


#Pairs with >1 original and 1 rerun were duplicate entries and rerun to determine which ID is correct. 
mixup<- wasMissing %>% filter(!is.na(parameterValue))


#make tnNew (finalized rows)
pocNew<- pocOld_missing %>% 
  add_column(sample = paste(pocOld_missing$sampleID, pocOld_missing$parameter,sep="_")) %>% 
  bind_rows(mixup) %>% #adds in U138 and U148 which were left out because they were mixed up
  filter(!sample %in% range$sample) %>%  #removes rows that need to be replaced by rows in range
  filter(!is.na(parameterValue)) %>% 
  bind_rows(range) %>% 
  select(colnames(pocOld_missing),flag) %>% 
  arrange(sampleID)

#check for dups or missing: good to go!
# dupList<-pocNew[duplicated(pocNew$sample),] 
# dup<-pocNew[pocNew$sample%in%dupList,] 
dup<- pocNew %>% 
  group_by(sampleID) %>%
  filter(n()>2)
#missing<- log$unfilteredID[!as.character(paste0("U",1:nrow(log))) %in% pocNew$sample]

#write.csv(pocNew, "Water/Output/compiledData/pocQCd_20210505.csv", row.names = F)
  